{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수집된 포털 정보기반 딥크롤링\n",
    "* 기존에 수집된 정보를 바탕으로 매체별 크롤링\n",
    "* 다양한 서브 데이터의 정형화\n",
    "* URL 기반의 다양한 크롤링 기법 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분석요소\n",
    "* 제목 :\n",
    "* 내용  :\n",
    "* 작성일 :\n",
    "* 매체: \n",
    "* 작성자:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기존 수집 데이터 활용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bsp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import re\n",
    "from datetime import datetime, timedelta,date\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcDate(txt=''):\n",
    "    #print(txt)\n",
    "    rdate=''\n",
    "    nowd=datetime.now()\n",
    "    pattern='[^\\d]'\n",
    "    num=int(re.sub(pattern,'',txt))\n",
    "    if('일' in txt):\n",
    "        res=nowd + timedelta(days=num*-1)\n",
    "    elif('.' in txt):\n",
    "        ds=txt.replace('.','-')\n",
    "        #print(ds)\n",
    "        res=ds+' 00:00:00.000000'\n",
    "    else:\n",
    "        res=nowd + timedelta(hours=num*-1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-2-1 00:00:00.000000'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcDate('2021.2.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeKey(txt=''):\n",
    "    txt_=re.sub('http\\S*//',' ',txt)\n",
    "    key=re.sub('[^a-zA-Z0-9%]','',txt_)\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(whr=''):\n",
    "    dbname='navernews.db'\n",
    "    with sqlite3.connect(dbname) as conn:\n",
    "        cursor=conn.cursor()\n",
    "        sql='select nidx,ncomp,nurl from nnews '+whr\n",
    "        res=cursor.execute(sql).fetchall()\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def insSub(d):\n",
    "    dbname='navernews.db'\n",
    "    d[7] = makeKey(d[6])\n",
    "    with sqlite3.connect(dbname) as conn:\n",
    "        cursor=conn.cursor()\n",
    "        sql='select * from subnews where skey=\"'+d[7]+'\"'\n",
    "        res=cursor.execute(sql).fetchall()\n",
    "        if(len(res)>0):\n",
    "            print(\"이미 존재 합니다.:\"+d[0])\n",
    "        else:\n",
    "            sql='insert into subnews (stitle,swriter,sday,sarticle,smidx,scompany,surl,skey) values(?,?,?,?,?,?,?,?)'\n",
    "            res=cursor.execute(sql,d)\n",
    "            print('.',end='')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setStat(index=0,stat=0):\n",
    "    dbname='navernews.db'\n",
    "    with sqlite3.connect(dbname) as conn:\n",
    "        cursor=conn.cursor()\n",
    "        sql='update nnews set nstat ={1} where nidx={0}'.format(index,nstat)\n",
    "        res=cursor.execute(sql)\n",
    "        if stat==1:\n",
    "            print('-',end='')\n",
    "        else:\n",
    "            print('=',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nstat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-08a2566a0e42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msetStat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m67\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-41-fd8fc666e22f>\u001b[0m in \u001b[0;36msetStat\u001b[1;34m(index, stat)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdbname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mcursor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0msql\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'update nnews set nstat ={1} where nidx={0}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnstat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstat\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nstat' is not defined"
     ]
    }
   ],
   "source": [
    "setStat(67,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAsia(urls):\n",
    "    url = urls[2]\n",
    "    res=requests.get(url)\n",
    "    src=res.content.strip()\n",
    "    htmls=bsp(src,'html.parser')\n",
    "    print(url)\n",
    "    title_block=htmls.select('div .area_title')[0]\n",
    "    wtitle=title_block.select('h3')[0].text.strip()\n",
    "    writer=htmls.select('.article_view > .article .e_article')[0].text.strip()\n",
    "    wday_=title_block.select('p.user_data')\n",
    "    wday = str(wday_).split('</strong>')[-1].replace('</p>]','').replace('.','-').strip()\n",
    "    article_=htmls.select('.article_view > .article ')[0]\n",
    "    pattern='<!-- 본문// -->[\\S\\s]*'\n",
    "    article__=re.sub(pattern,' ',str(article_))\n",
    "#     pattern='<div id=\"bestnews_layer\">.*'\n",
    "#     article__=re.sub(pattern,' ',str(article__))\n",
    "    warticle=bsp(article__,'html.parser').text.strip()\n",
    "    return [wtitle,writer,wday,warticle,urls[0],urls[1],urls[2]]\n",
    "    #return [wtitle,wday,urls[0],urls[1],urls[2]]\n",
    "urls = (69,'아시아경제','https://view.asiae.co.kr/article/2021031715545233623')\n",
    "#print(getAsia(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDonga(urls):\n",
    "    url = urls[2]\n",
    "    res=requests.get(url)\n",
    "    src=res.content.strip()\n",
    "    htmls=bsp(src,'html.parser')\n",
    "    print(url)\n",
    "    title_block=htmls.select('div .article_title')[0]\n",
    "    wtitle=title_block.select('h1.title')[0].text.strip()\n",
    "    writer=title_block.select('span.report')[0].text.replace('동아닷컴 기자','').strip()\n",
    "    wday=title_block.select('span.date01')[-1].text.strip()\n",
    "    article_=htmls.select('div.article_txt')[0]\n",
    "    pattern='<script[^>]*>((\\n|\\r|.)*?)<\\/script>'\n",
    "    article__=re.sub(pattern,' ',str(article_))\n",
    "    pattern='<div id=\"bestnews_layer\">.*'\n",
    "    article__=re.sub(pattern,' ',str(article__))\n",
    "    warticle=bsp(article__,'html.parser').text\n",
    "    return [wtitle,writer,wday,warticle,urls[0],urls[1],urls[2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def getDona(url):\n",
    "    res=requests.get(url)\n",
    "    src=res.content.strip()\n",
    "    htmls=bsp(src,'html.parser')\n",
    "    print(url)\n",
    "    title_block=htmls.select('div .article_title')\n",
    "    if(len(tgts)==0):\n",
    "        print('데이터가 없습니다.'+url)\n",
    "        sys.exit(1)\n",
    "    for tgt in tgts:\n",
    "        mainarti=tgt.select('div .news_wrap')\n",
    "        subartis=tgt.select('ul .list_cluster > li .sub_bx')\n",
    "        if(len(mainarti)>0):\n",
    "            title_= mainarti[0].select('a .news_tit')[0].text\n",
    "            title=re.sub('[^ㄱ-힣0-9 a-zA-Z]',' ',title_)\n",
    "            comp=mainarti[0].select('.info.press')[0].text.replace('언론사 선정','')\n",
    "            date_=mainarti[0].select('span.info')[0].text.replace('시간 전','')\n",
    "            date=calcDate(date_)\n",
    "            url=mainarti[0].select('a .news_tit')[0]['href']\n",
    "            key=makeKey(url)\n",
    "            opt=1\n",
    "            d=(opt,title,comp,date,url,key)\n",
    "            insMain(d)\n",
    "            for subarti in subartis:\n",
    "                title_= subarti.select('a .sub_tit')[0].text\n",
    "                title=re.sub('[^ㄱ-힣0-9 a-zA-Z]',' ',title_)\n",
    "                comp=subarti.select('.sub_txt.press')[0].text.replace('언론사 선정','')\n",
    "                date_=subarti.select('span.sub_txt')[0].text.replace('시간 전','').replace('네이버뉴스','')\n",
    "                date=calcDate(date_)\n",
    "                url=subarti.select('a .sub_tit')[0]['href']\n",
    "                key=makeKey(url)\n",
    "                opt=2\n",
    "                d=(opt,title,comp,date,url,key)\n",
    "                insMain(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비동기 페이지\n",
    "* 크롬 드라이버 활용\n",
    "* 다운로드 : https://sites.google.com/a/chromium.org/chromedriver/downloads\n",
    "* 해당 크롬 버전에 맞는 드라이버 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bsp\n",
    "\n",
    "driver = webdriver.Chrome('C:/asi/project/chromedriver_win32 (3)/chromedriver')\n",
    "url = ('https://www.chosun.com/economy/market_trend/2021/03/17/7O5JTHZSJVAJBFMUWNJGK22XUA/')\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(3)\n",
    "html = driver.page_source\n",
    "src = bsp(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ('https://www.chosun.com/economy/market_trend/2021/03/17/7O5JTHZSJVAJBFMUWNJGK22XUA/')\n",
    "urls = ['327','조선일보',url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChosun(urls):\n",
    "    url = urls[2]\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(3)\n",
    "    html = driver.page_source\n",
    "    src = bsp(html,'html.parser')\n",
    "    wtitle = src.select('h1.article-header__headline')[0].text\n",
    "    writer = src.select('a.article-byline__author')[0].text.replace('기자','').strip()\n",
    "    wdate_ = src.select('div .article-dateline')[0].text.split(\"|\")[-1]\n",
    "    wday = wdate_.replace('수정','').replace('.','-').strip()+':00'\n",
    "    warticle = src.select('section.article-body')[0].text.replace('\\xad','')\n",
    "    #urls : main_index, company, url\n",
    "    return [wtitle,writer,wday,warticle,urls[0],urls[1],urls[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['신세계·네이버 2500억 지분 교환… 쿠팡에 맞서는 온·오프라인 동맹', '변희원', '2021-03-17 03:00:00', '이커머스 시장을 차지하기 위한 온·오프라인 유통업체 간의 합종연횡이 본격화되고 있다.네이버와 신세계는 16일 2500억원 상당의 지분을 교환하는 방식의 사업 제휴를 발표했다. 네이버는 이날 신세계인터내셔널 지분 1000억원어치와 이마트 지분 1500억원을 취득한다고 공시했다. 지난 1월 정용진 신세계 부회장이 네이버 성남 사옥을 방문해 이해진 네이버 창업자 겸 글로벌투자책임자(GIO)를 만나 협력을 제안한 이후 두 달 만에 제휴가 구체화된 것이다.유통업계에서는 온라인 상거래 1위 업체 네이버와 오프라인 쇼핑 강자인 신세계가 예상보다 빨리 손을 잡은 것은 최근 쿠팡이 뉴욕 증시에 상장한데다 이베이코리아 인수전까지 벌어진 이커머스 판도에 발빠른 대응을 하기 위해서란 분석이 나온다. 신세계 관계자는 “현시점에 제휴를 하지 않으면 실기(失期)를 할 수 있단 생각에 (지분 교환이) 빠르게 진행됐다”고 했다.신세계의 온라인 쇼핑몰 ‘쓱닷컴’은 지난해 이커머스 시장 점유율이 2.4%에 불과하다. 시장 점유율 1위인 네이버쇼핑과 협력하면서 온라인 시장에서의 영향력을 키우겠다는 전략이다. 네이버 입장에서는 신세계 이마트가 강점을 갖고 있는 신선식품이나 도심 내 오프라인 매장을 기반으로 한 당일 배송을 본격적으로 추진할 수 있다. 한 업계 관계자는 “두 회사가 각각 가진 장점이 뚜렷한 만큼, 이번 제휴를 통해 서로의 약점을 보완하고 시너지 효과를 낼 수 있다고 판단한 것 같다”고 말했다. 네이버는 지난해 10월 CJ그룹과도 6000억원 규모의 지분을 교환한 바 있다.한편 이날 이베이코리아 예비 입찰도 마감됐다. 이마트, 롯데, 홈플러스 대주주인 MBK파트너스, SK텔레콤 등이 예비 입찰에 참여했다.', '327', '조선일보', 'https://www.chosun.com/economy/market_trend/2021/03/17/7O5JTHZSJVAJBFMUWNJGK22XUA/']\n"
     ]
    }
   ],
   "source": [
    "res = getChosun(urls)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "allurl=getData()\n",
    "allurl[:5]\n",
    "for urls in allurl[:3]:\n",
    "    print('-'*50)\n",
    "    wdata=''\n",
    "    #print(nidx,ncomp,turl)\n",
    "    if urls[1]==\"동아일보\":\n",
    "        wdata=getDonga(urls)\n",
    "    elif urls[1]==\"아시아경제\":\n",
    "        wdata=getAsia(urls)\n",
    "    elif urls[1]==\"조선일보\":\n",
    "        wdata=getChosun(urls)\n",
    "    print(wdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
